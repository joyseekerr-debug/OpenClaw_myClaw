# Phase 3-16: 参数优化方法

## 一、概念定义

### 1.1 参数优化的目标
在策略开发中找到最优的参数组合，使策略在历史数据上表现最佳，同时保持对未来数据的泛化能力。

**核心挑战：**
```
优化 vs 泛化的平衡：
• 充分优化：挖掘策略潜力
• 避免过拟合：保持稳健性
• 计算效率：在合理时间内完成
```

### 1.2 参数类型

**策略参数**
```
趋势类：
• 均线周期（5日、10日、20日等）
• 突破阈值（百分比、标准差倍数）
• 确认周期

均值回复类：
• 回看周期
• 偏离阈值（Z-score阈值）
• 持有周期

风险控制：
• 止损比例
• 止盈比例
• 仓位上限
```

**模型参数**
```
机器学习模型：
• 学习率
• 正则化强度
• 树的数量和深度
• 网络层数和宽度

特征工程：
• 窗口大小
• 平滑系数
• 分位数阈值
```

### 1.3 优化问题的特性

**多峰性（Multi-modal）**
```
特征：
• 多个局部最优解
• 参数空间非凸
• 优化方法可能陷入局部最优

示例：
• 不同周期可能都有不错表现
• 短周期 vs 长周期策略
• 需要全局搜索方法
```

**噪声（Noisiness）**
```
特征：
• 目标函数（策略收益）有随机性
• 相同参数多次运行结果不同
• 难以精确评估

影响：
• 梯度估计困难
• 需要多次采样平均
• 容忍一定误差
```

**计算昂贵**
```
特征：
• 每次评估需要完整回测
• 参数组合数量指数增长
• 时间成本高昂

应对：
• 代理模型
• 并行计算
• 早停策略
```

---

## 二、算法原理

### 2.1 网格搜索（Grid Search）

**原理**
```
方法：
• 对每个参数定义离散取值范围
• 遍历所有参数组合
• 评估每个组合的表现
• 选择最优组合

示例：
参数A：[10, 20, 30]
参数B：[0.01, 0.02, 0.03]
组合数：3 × 3 = 9种
```

**优缺点**
```
优点：
• 简单直观
• 可并行化
• 能找到全局最优（在离散范围内）

缺点：
• 维度灾难：组合数指数增长
• 精度受限：只能找到网格点
• 计算浪费：均匀采样，不考虑已有结果

适用场景：
• 参数维度低（1-3个）
• 计算资源充足
• 需要精确结果
```

### 2.2 随机搜索（Random Search）

**原理**
```
方法：
• 在参数空间随机采样
• 评估固定次数的随机组合
• 选择最优

理论依据：
• 通常只有少量参数重要
• 随机搜索能更高效地发现重要参数
• 对低有效维度问题尤其有效
```

**与网格搜索对比**
```
效率优势：
• 60次随机搜索 ≈ 网格搜索覆盖每个维度5个值
• 在高维空间优势明显

实践建议：
• 参数维度 > 3时优先随机搜索
• 预算有限时优先随机搜索
• 对连续参数更有效
```

### 2.3 贝叶斯优化（Bayesian Optimization）

**核心思想**
```
构建代理模型：
• 用高斯过程（GP）拟合参数-表现映射
• 基于已有评估点，推断未评估点的表现分布
• 选择最有"潜力"的点进行评估

采集函数（Acquisition Function）：
• 平衡探索（exploration）和利用（exploitation）
• Upper Confidence Bound（UCB）
• Expected Improvement（EI）
• Probability of Improvement（PI）
```

**高斯过程基础**
```
特性：
• 定义在函数空间上的分布
• 任意有限点的取值服从联合高斯分布
• 由均值函数和协方差函数（核函数）决定

核函数（Kernel）：
• 衡量参数点之间的相似性
• 常用RBF（径向基函数）核
• 决定函数的平滑程度

后验更新：
• 观测到新数据后更新GP
• 改进对目标函数的估计
• 指导下一轮采样
```

**算法流程**
```
1. 初始化：随机采样几个点评估
2. 拟合GP：用已评估点训练高斯过程
3. 优化采集函数：找到下一个评估点
4. 评估目标函数：在新点评估策略
5. 更新：加入新数据，回到步骤2
6. 重复直到预算用完或收敛
```

**优缺点**
```
优点：
• 样本效率高（比网格/随机搜索用更少评估）
• 能处理噪声
• 能捕捉参数间的交互

缺点：
• 实现复杂
• 高维问题效果下降（>20维）
• GP计算成本随样本数立方增长

适用场景：
• 评估成本高（每次回测耗时）
• 参数维度中等（5-20个）
• 需要高效利用预算
```

### 2.4 遗传算法（Genetic Algorithm）

**原理**
```
模拟自然选择：
• 种群：一组参数组合
• 选择：保留表现好的个体
• 交叉：组合两个优秀个体的参数
• 变异：随机扰动参数
• 迭代：重复进化多代
```

**算法流程**
```
1. 初始化：随机生成种群
2. 评估：计算每个个体的适应度（策略表现）
3. 选择：根据适应度选择父母
   （轮盘赌、锦标赛选择等）
4. 交叉：父母基因重组产生后代
5. 变异：随机改变部分参数
6. 新一代：用后代替换部分或全部种群
7. 重复2-6直到收敛或达到代数
```

**特点**
```
优点：
• 适合非连续、非凸问题
• 能逃离局部最优
• 天然并行化

缺点：
• 需要调参（种群大小、交叉率、变异率）
• 收敛慢
• 结果有一定随机性

适用场景：
• 离散参数优化
• 复杂约束问题
• 全局搜索需求强
```

### 2.5  Walk-Forward优化

**原理**
```
滚动优化：
• 将数据分为多个窗口
• 每个窗口内部分为训练期和验证期
• 在训练期优化参数
• 在验证期评估表现
• 前向推进，重复过程

目的：
• 模拟实盘使用方式
• 评估参数稳定性
• 减少过拟合风险
```

**实现方式**
```
方式1：滚动窗口（Rolling Window）
[Train1] [Test1]
   [Train2] [Test2]
      [Train3] [Test3]

方式2：扩展窗口（Expanding Window）
[Train1] [Test1]
[----Train2----] [Test2]
[------Train3------] [Test3]

方式3：锚定窗口（Anchored Walk-forward）
固定训练期长度，定期重优化
```

**与交叉验证的区别**
```
交叉验证：
• 目的是评估模型泛化能力
• 选择最优超参数

Walk-forward：
• 模拟实际交易中的参数更新
• 评估参数稳定性
• 计算更真实的预期表现
```

---

## 三、应用场景

### 3.1 量化策略参数优化

**均线策略优化**
```
参数：
• 短期均线周期：5-20日
• 长期均线周期：20-60日
• 确认周期：1-3日

方法选择：
• 2-3个参数 → 网格搜索或随机搜索
• 评估指标：夏普比率、最大回撤
• 稳健性检验：参数平面是否平滑
```

**均值回复策略优化**
```
参数：
• 回看周期：10-60日
• Z-score阈值：1.5-3.0
• 持有周期：5-20日

注意事项：
• 阈值与周期通常相关
• 需要联合优化
• 关注参数的稳定性
```

### 3.2 机器学习超参数优化

**XGBoost优化**
```
关键参数：
• max_depth：3-10
• learning_rate：0.01-0.3
• n_estimators：100-1000
• subsample：0.6-1.0
• colsample_bytree：0.6-1.0
• reg_alpha/reg_lambda：0-1

方法：
• 贝叶斯优化（推荐）
• 随机搜索
• 分阶段优化（先树结构，后正则化）
```

**神经网络优化**
```
超参数：
• 学习率：最重要，通常1e-4到1e-2
• batch size：16-256
• 层数：1-5
• 每层单元数：32-512
• dropout率：0-0.5
• 优化器：Adam、SGD等

方法：
• 学习率单独调（学习率范围测试）
• 其他参数贝叶斯优化
• 早停减少搜索时间
```

### 3.3 组合优化

**多策略权重优化**
```
目标：
• 最大化组合夏普比率
• 控制风险暴露
• 满足约束条件

方法：
• 均值-方差优化（MVO）
• 风险平价（Risk Parity）
• Black-Litterman模型
• 机器学习优化（如强化学习）
```

**风险预算优化**
```
目标：
• 各策略风险贡献相等
• 或按目标比例分配

计算：
• 边际风险贡献
• 风险贡献 = 权重 × 边际风险贡献
• 优化使风险贡献匹配目标
```

---

## 四、注意事项

### 4.1 过拟合防范

**参数数量控制**
```
原则：
• 参数越多，过拟合风险越大
• 每个参数都需要"付出代价"
• 简单策略优先

经验法则：
• 参数数量与数据量匹配
• 参数数量与回测期长度匹配
• 参数数量与交易次数匹配
```

**稳健性检验**
```
方法：
• 参数平面分析：观察最优参数邻域
• 蒙特卡洛测试：参数扰动测试
• 不同子样本优化：检验参数稳定性

接受标准：
• 最优参数不是孤立的尖峰
• 微小参数变化不会导致表现剧变
• 不同子样本的最优参数相近
```

**样本外验证**
```
必须：
• 优化只在训练/验证集上进行
• 测试集绝对不能参与优化
• 使用walk-forward评估优化效果

警告信号：
• 训练集表现远好于验证集
• 参数对数据子集敏感
• 最优参数过于"精确"
```

### 4.2 计算效率

**并行化策略**
```
方法：
• 多进程：每个进程评估不同参数
• 分布式：多台机器并行
• GPU加速：适合神经网络

注意事项：
• 随机种子设置（保证可复现）
• 资源分配平衡
• 结果聚合
```

**早停策略**
```
原理：
• 在优化过程中识别无潜力的参数组合
• 提前终止评估，节省计算

应用：
• 如果初期表现极差，提前停止完整回测
• 设置最低表现门槛
• 逐步增加评估精度
```

### 4.3 离散与连续参数

**混合参数类型**
```
离散参数：
• 窗口大小（整数）
• 布尔选择（是/否）
• 类别选择（方法A/B/C）

连续参数：
• 阈值（浮点数）
• 比例（0-1之间）
• 学习率

处理方法：
• 贝叶斯优化：连续参数直接使用，离散参数取整
• 遗传算法：自然处理混合类型
• 网格搜索：离散化连续参数
```

### 4.4 约束处理

**常见约束**
```
单调约束：
• 短周期 < 长周期
• 止损 < 止盈

范围约束：
• 参数在合理范围内
• 权重之和为1

经济约束：
• 参数有经济意义
• 避免极端值
```

**约束优化方法**
```
惩罚函数：
• 违反约束时增加惩罚项
• 将约束问题转为无约束

投影方法：
• 将无效参数投影到可行域
• 保持优化方向

直接处理：
• 贝叶斯优化中直接处理约束
• 遗传算法中只生成可行解
```

---

## 五、核心概念总结

```
┌─────────────────────────────────────────────────────────┐
│                参数优化方法核心框架                      │
├─────────────────────────────────────────────────────────┤
│  基础方法                                              │
│  ├── 网格搜索：穷举所有组合，适合低维（1-3个参数）      │
│  └── 随机搜索：随机采样，适合高维，效率高于网格         │
├─────────────────────────────────────────────────────────┤
│  智能优化                                              │
│  ├── 贝叶斯优化：代理模型+采集函数，样本效率高          │
│  │   └── 适合：评估昂贵、参数维度中等（5-20）           │
│  └── 遗传算法：模拟进化，适合非凸、离散问题             │
│      └── 适合：全局搜索、复杂约束                       │
├─────────────────────────────────────────────────────────┤
│  时序适配                                              │
│  └── Walk-forward：滚动优化，模拟实盘使用方式           │
│      └── 目的：评估参数稳定性，减少过拟合               │
├─────────────────────────────────────────────────────────┤
│  关键原则                                              │
│  ├── 防范过拟合：参数数量控制、稳健性检验               │
│  ├── 样本外验证：测试集绝不参与优化                     │
│  ├── 经济意义：参数值应有合理解释                       │
│  └── 计算效率：并行化、早停、分阶段优化                 │
├─────────────────────────────────────────────────────────┤
│  选择指南                                              │
│  ├── 参数少（1-3）：网格搜索                            │
│  ├── 参数多（3-10）：随机搜索或贝叶斯优化               │
│  ├── 评估昂贵：贝叶斯优化                               │
│  ├── 离散参数多：遗传算法                               │
│  └── 时序策略：Walk-forward优化                         │
└─────────────────────────────────────────────────────────┘
```

---

*文档创建时间：2026-02-24*  
*所属阶段：Phase 3 - 量化技能（第16/20项）*
