"""
ç‰¹å¾å·¥ç¨‹ä¸»æ¨¡å—
æ•´åˆæŠ€æœ¯æŒ‡æ ‡ã€Alphaå› å­ã€ç‰¹å¾ç¼“å­˜
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional
import logging

from features.technical import TechnicalIndicatorCalculator
from features.alpha import AlphaFactorCalculator
from utils.cache import FeatureCache, get_cache

logger = logging.getLogger(__name__)


class FeatureEngine:
    """ç‰¹å¾å·¥ç¨‹ä¸»ç±»"""
    
    def __init__(self, use_cache: bool = True):
        self.technical_calc = TechnicalIndicatorCalculator()
        self.alpha_calc = AlphaFactorCalculator()
        self.use_cache = use_cache
        
        if use_cache:
            self.cache = FeatureCache(get_cache())
            logger.info("âœ… ç‰¹å¾ç¼“å­˜å·²å¯ç”¨")
        else:
            self.cache = None
            logger.info("âš ï¸ ç‰¹å¾ç¼“å­˜å·²ç¦ç”¨")
    
    def calculate_features(self, df: pd.DataFrame, symbol: str,
                          use_cache: bool = True) -> pd.DataFrame:
        """
        è®¡ç®—æ‰€æœ‰ç‰¹å¾
        
        Args:
            df: åŸå§‹OHLCVæ•°æ®
            symbol: è‚¡ç¥¨ä»£ç ï¼Œç”¨äºç¼“å­˜
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        
        Returns:
            åŒ…å«æ‰€æœ‰ç‰¹å¾çš„DataFrame
        """
        if df.empty:
            logger.warning("è¾“å…¥æ•°æ®ä¸ºç©º")
            return df
        
        # ç¡®ä¿æœ‰timestampåˆ—
        if 'timestamp' not in df.columns:
            df['timestamp'] = df.index
        
        result = df.copy()
        
        # é€è¡Œè®¡ç®—ç‰¹å¾ï¼ˆæ”¯æŒç¼“å­˜ï¼‰
        if use_cache and self.cache:
            result = self._calculate_with_cache(result, symbol)
        else:
            # æ‰¹é‡è®¡ç®—ï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼‰
            result = self.technical_calc.calculate_all(result)
            result = self.alpha_calc.calculate_all(result)
        
        # å¡«å……NaNå€¼
        result = self._fill_na(result)
        
        logger.info(f"âœ… ç‰¹å¾è®¡ç®—å®Œæˆ: {len(result.columns)} åˆ—, {len(result)} è¡Œ")
        
        return result
    
    def _calculate_with_cache(self, df: pd.DataFrame, symbol: str) -> pd.DataFrame:
        """ä½¿ç”¨ç¼“å­˜è®¡ç®—ç‰¹å¾"""
        result = df.copy()
        
        # éœ€è¦è®¡ç®—çš„æŠ€æœ¯æŒ‡æ ‡åˆ—è¡¨
        tech_features = self.technical_calc.get_feature_names()
        alpha_features = self.alpha_calc.get_alpha_feature_names()
        all_features = tech_features + alpha_features
        
        # æ£€æŸ¥å“ªäº›ç‰¹å¾éœ€è¦è®¡ç®—
        missing_features = set()
        
        for timestamp in result['timestamp']:
            ts_str = str(timestamp)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_features = {}
            for feat_name in all_features:
                cached_value = self.cache.get_feature(symbol, ts_str, feat_name)
                if cached_value is not None:
                    cached_features[feat_name] = cached_value
            
            # è®°å½•ç¼ºå¤±çš„ç‰¹å¾
            for feat_name in all_features:
                if feat_name not in cached_features:
                    missing_features.add(feat_name)
        
        if missing_features:
            logger.info(f"éœ€è¦è®¡ç®— {len(missing_features)} ä¸ªç¼ºå¤±ç‰¹å¾")
            
            # æ‰¹é‡è®¡ç®—æ‰€æœ‰ç‰¹å¾
            result = self.technical_calc.calculate_all(result)
            result = self.alpha_calc.calculate_all(result)
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self._save_to_cache(result, symbol, all_features)
        else:
            logger.info("æ‰€æœ‰ç‰¹å¾å‡å·²ç¼“å­˜")
        
        return result
    
    def _save_to_cache(self, df: pd.DataFrame, symbol: str, feature_names: List[str]):
        """ä¿å­˜ç‰¹å¾åˆ°ç¼“å­˜"""
        if not self.cache:
            return
        
        for _, row in df.iterrows():
            timestamp = str(row['timestamp'])
            
            for feat_name in feature_names:
                if feat_name in row and pd.notna(row[feat_name]):
                    self.cache.set_feature(
                        symbol, timestamp, feat_name, float(row[feat_name])
                    )
        
        logger.info(f"ğŸ’¾ å·²ç¼“å­˜ {len(df)} è¡Œæ•°æ®")
    
    def _fill_na(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¡«å……ç¼ºå¤±å€¼"""
        # å‘å‰å¡«å……
        df = df.fillna(method='ffill')
        
        # å‘åå¡«å……ï¼ˆå¤„ç†å¼€å¤´çš„NaNï¼‰
        df = df.fillna(method='bfill')
        
        # å‰©ä½™çš„å¡«å……ä¸º0
        df = df.fillna(0)
        
        return df
    
    def get_feature_importance(self, df: pd.DataFrame, target_col: str = 'close') -> Dict[str, float]:
        """
        è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºç›¸å…³ç³»æ•°ï¼‰
        
        Args:
            df: åŒ…å«ç‰¹å¾çš„DataFrame
            target_col: ç›®æ ‡åˆ—
        
        Returns:
            ç‰¹å¾é‡è¦æ€§å­—å…¸
        """
        # è®¡ç®—ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        correlations = {}
        
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡ä½œä¸ºç›®æ ‡
        if 'returns' not in df.columns:
            df['future_returns'] = df[target_col].shift(-1) / df[target_col] - 1
        else:
            df['future_returns'] = df['returns'].shift(-1)
        
        feature_cols = [c for c in df.columns if c not in 
                       ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'future_returns']]
        
        for col in feature_cols:
            corr = df[col].corr(df['future_returns'])
            if pd.notna(corr):
                correlations[col] = abs(corr)
        
        # æ’åº
        sorted_corr = dict(sorted(correlations.items(), key=lambda x: x[1], reverse=True))
        
        return sorted_corr
    
    def select_top_features(self, df: pd.DataFrame, n_features: int = 50,
                           target_col: str = 'close') -> List[str]:
        """
        é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾
        
        Args:
            df: åŒ…å«ç‰¹å¾çš„DataFrame
            n_features: é€‰æ‹©ç‰¹å¾æ•°é‡
            target_col: ç›®æ ‡åˆ—
        
        Returns:
            é€‰ä¸­çš„ç‰¹å¾ååˆ—è¡¨
        """
        importance = self.get_feature_importance(df, target_col)
        
        top_features = list(importance.keys())[:n_features]
        
        logger.info(f"é€‰æ‹©å‰ {len(top_features)} ä¸ªé‡è¦ç‰¹å¾")
        
        return top_features
    
    def create_sequences(self, df: pd.DataFrame, feature_cols: List[str],
                        target_col: str, sequence_length: int = 60) -> tuple:
        """
        åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®ï¼ˆç”¨äºæ·±åº¦å­¦ä¹ ï¼‰
        
        Args:
            df: ç‰¹å¾DataFrame
            feature_cols: ç‰¹å¾åˆ—å
            target_col: ç›®æ ‡åˆ—å
            sequence_length: åºåˆ—é•¿åº¦
        
        Returns:
            X, y æ•°ç»„
        """
        X, y = [], []
        
        data = df[feature_cols].values
        target = df[target_col].values
        
        for i in range(len(data) - sequence_length):
            X.append(data[i:(i + sequence_length)])
            y.append(target[i + sequence_length])
        
        return np.array(X), np.array(y)
    
    def normalize_features(self, df: pd.DataFrame, feature_cols: List[str],
                          method: str = 'zscore') -> pd.DataFrame:
        """
        ç‰¹å¾å½’ä¸€åŒ–
        
        Args:
            df: ç‰¹å¾DataFrame
            feature_cols: éœ€è¦å½’ä¸€åŒ–çš„ç‰¹å¾åˆ—
            method: 'zscore' æˆ– 'minmax'
        
        Returns:
            å½’ä¸€åŒ–åçš„DataFrame
        """
        result = df.copy()
        
        for col in feature_cols:
            if col in result.columns:
                if method == 'zscore':
                    mean = result[col].mean()
                    std = result[col].std()
                    if std != 0:
                        result[col] = (result[col] - mean) / std
                elif method == 'minmax':
                    min_val = result[col].min()
                    max_val = result[col].max()
                    if max_val != min_val:
                        result[col] = (result[col] - min_val) / (max_val - min_val)
        
        return result
    
    def get_all_feature_names(self) -> List[str]:
        """è·å–æ‰€æœ‰ç‰¹å¾åç§°"""
        tech_features = self.technical_calc.get_feature_names()
        alpha_features = self.alpha_calc.get_alpha_feature_names()
        return tech_features + alpha_features


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2024-01-01', periods=100, freq='D')
    
    base_price = 15.0
    prices = [base_price]
    for i in range(99):
        change = np.random.normal(0.001, 0.02)
        prices.append(prices[-1] * (1 + change))
    
    df = pd.DataFrame({
        'timestamp': dates,
        'open': [p * np.random.uniform(0.995, 1.0) for p in prices],
        'high': [p * np.random.uniform(1.0, 1.02) for p in prices],
        'low': [p * np.random.uniform(0.98, 1.0) for p in prices],
        'close': prices,
        'volume': np.random.randint(1000000, 10000000, 100)
    })
    
    # åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹
    engine = FeatureEngine(use_cache=False)
    
    # è®¡ç®—ç‰¹å¾
    result = engine.calculate_features(df, symbol='1810.HK')
    
    print(f"\nâœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ!")
    print(f"è¾“å…¥åˆ—æ•°: {len(df.columns)}")
    print(f"è¾“å‡ºåˆ—æ•°: {len(result.columns)}")
    print(f"æ–°å¢ç‰¹å¾: {len(result.columns) - len(df.columns)}")
    
    # ç‰¹å¾é‡è¦æ€§
    importance = engine.get_feature_importance(result)
    print("\nğŸ” å‰10ä¸ªé‡è¦ç‰¹å¾:")
    for feat, score in list(importance.items())[:10]:
        print(f"  {feat}: {score:.4f}")
    
    # é€‰æ‹©Topç‰¹å¾
    top_features = engine.select_top_features(result, n_features=30)
    print(f"\nâœ… å·²é€‰æ‹© {len(top_features)} ä¸ªç‰¹å¾ç”¨äºå»ºæ¨¡")
