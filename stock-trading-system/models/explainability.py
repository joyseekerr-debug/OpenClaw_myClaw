"""
SHAPæ¨¡å‹è§£é‡Šæ€§åˆ†æ
è§£é‡Šæ¨¡å‹é¢„æµ‹ç»“æœå’Œç‰¹å¾è´¡çŒ®
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SHAPExplainer:
    """SHAPè§£é‡Šå™¨"""
    
    def __init__(self, model, model_type: str = 'tree'):
        """
        åˆå§‹åŒ–SHAPè§£é‡Šå™¨
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            model_type: 'tree' (XGBoost/LightGBM) æˆ– 'deep' (LSTM/Transformer)
        """
        self.model = model
        self.model_type = model_type
        self.explainer = None
        self.shap_values = None
        
    def build_explainer(self, X_background: Optional[np.ndarray] = None):
        """
        æ„å»ºSHAPè§£é‡Šå™¨
        
        Args:
            X_background: èƒŒæ™¯æ•°æ®ï¼ˆç”¨äºè§£é‡Šï¼‰
        """
        try:
            import shap
            
            if self.model_type == 'tree':
                # æ ‘æ¨¡å‹ä½¿ç”¨TreeExplainer
                self.explainer = shap.TreeExplainer(self.model.model)
                logger.info("âœ… TreeExplaineræ„å»ºå®Œæˆ")
                
            elif self.model_type == 'deep':
                # æ·±åº¦å­¦ä¹ æ¨¡å‹ä½¿ç”¨DeepExplainer
                if X_background is None:
                    raise ValueError("æ·±åº¦å­¦ä¹ æ¨¡å‹éœ€è¦æä¾›èƒŒæ™¯æ•°æ®")
                
                import torch
                self.explainer = shap.DeepExplainer(self.model.model, 
                                                   torch.FloatTensor(X_background))
                logger.info("âœ… DeepExplaineræ„å»ºå®Œæˆ")
                
            else:
                # å…¶ä»–æ¨¡å‹ä½¿ç”¨KernelExplainer
                if X_background is None:
                    raise ValueError("KernelExplaineréœ€è¦æä¾›èƒŒæ™¯æ•°æ®")
                
                self.explainer = shap.KernelExplainer(self.model.predict, X_background)
                logger.info("âœ… KernelExplaineræ„å»ºå®Œæˆ")
                
        except ImportError:
            logger.error("âŒ SHAPåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨è§£é‡ŠåŠŸèƒ½")
            raise
    
    def explain(self, X: np.ndarray, feature_names: List[str]) -> Dict[str, Any]:
        """
        è§£é‡Šé¢„æµ‹ç»“æœ
        
        Args:
            X: å¾…è§£é‡Šçš„ç‰¹å¾æ•°æ®
            feature_names: ç‰¹å¾åç§°
        
        Returns:
            SHAPè§£é‡Šç»“æœ
        """
        if self.explainer is None:
            logger.warning("âš ï¸ è§£é‡Šå™¨æœªæ„å»ºï¼Œå°è¯•è‡ªåŠ¨æ„å»º...")
            self.build_explainer()
        
        try:
            import shap
            
            # è®¡ç®—SHAPå€¼
            self.shap_values = self.explainer.shap_values(X)
            
            # å¤„ç†å¤šè¾“å‡ºæƒ…å†µï¼ˆå–ç¬¬ä¸€ä¸ªè¾“å‡ºï¼‰
            if isinstance(self.shap_values, list):
                self.shap_values = self.shap_values[0]
            
            # æ„å»ºè§£é‡Šç»“æœ
            results = {
                'shap_values': self.shap_values,
                'base_value': self.explainer.expected_value,
                'feature_names': feature_names,
                'feature_importance': self._calculate_feature_importance(feature_names)
            }
            
            logger.info(f"âœ… SHAPè§£é‡Šå®Œæˆ: {len(feature_names)} ä¸ªç‰¹å¾")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ SHAPè§£é‡Šå¤±è´¥: {e}")
            raise
    
    def _calculate_feature_importance(self, feature_names: List[str]) -> pd.DataFrame:
        """è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºSHAPå€¼ç»å¯¹å€¼çš„å¹³å‡ï¼‰"""
        if self.shap_values is None:
            return pd.DataFrame()
        
        # è®¡ç®—å¹³å‡ç»å¯¹SHAPå€¼
        mean_shap = np.abs(self.shap_values).mean(axis=0)
        
        # å¦‚æœæ˜¯åºåˆ—æ•°æ®ï¼Œéœ€è¦å±•å¹³
        if len(mean_shap.shape) > 1:
            mean_shap = mean_shap.flatten()
        
        # æ„å»ºDataFrame
        importance_df = pd.DataFrame({
            'feature': feature_names[:len(mean_shap)],
            'shap_importance': mean_shap[:len(feature_names)]
        })
        
        importance_df = importance_df.sort_values('shap_importance', ascending=False)
        
        return importance_df
    
    def explain_single_prediction(self, X: np.ndarray, feature_names: List[str],
                                 idx: int = 0) -> Dict[str, Any]:
        """
        è§£é‡Šå•ä¸ªé¢„æµ‹ç»“æœ
        
        Args:
            X: ç‰¹å¾æ•°æ®
            feature_names: ç‰¹å¾åç§°
            idx: æ ·æœ¬ç´¢å¼•
        
        Returns:
            å•æ ·æœ¬è§£é‡Šç»“æœ
        """
        if self.shap_values is None:
            self.explain(X, feature_names)
        
        # è·å–æŒ‡å®šæ ·æœ¬çš„SHAPå€¼
        sample_shap = self.shap_values[idx]
        
        # å¦‚æœæ˜¯åºåˆ—æ•°æ®ï¼Œå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        if len(sample_shap.shape) > 1:
            sample_shap = sample_shap[-1]
        
        # ç‰¹å¾è´¡çŒ®
        contributions = []
        for i, (name, shap_val) in enumerate(zip(feature_names, sample_shap)):
            contributions.append({
                'feature': name,
                'shap_value': shap_val,
                'impact': 'æ­£å‘' if shap_val > 0 else 'è´Ÿå‘',
                'magnitude': abs(shap_val)
            })
        
        # æŒ‰è´¡çŒ®ç»å¯¹å€¼æ’åº
        contributions.sort(key=lambda x: x['magnitude'], reverse=True)
        
        return {
            'base_value': self.explainer.expected_value,
            'prediction': self.explainer.expected_value + np.sum(sample_shap),
            'top_features': contributions[:10],
            'all_contributions': contributions
        }
    
    def plot_summary(self, X: np.ndarray, feature_names: List[str],
                    save_path: Optional[str] = None):
        """
        ç»˜åˆ¶SHAPæ‘˜è¦å›¾
        
        Args:
            X: ç‰¹å¾æ•°æ®
            feature_names: ç‰¹å¾åç§°
            save_path: ä¿å­˜è·¯å¾„
        """
        try:
            import shap
            import matplotlib.pyplot as plt
            
            if self.shap_values is None:
                self.explain(X, feature_names)
            
            plt.figure(figsize=(10, 8))
            shap.summary_plot(self.shap_values, X, feature_names=feature_names,
                            show=False)
            plt.title("SHAP Feature Importance")
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"ğŸ“Š SHAPæ‘˜è¦å›¾å·²ä¿å­˜: {save_path}")
            
            plt.show()
            
        except ImportError:
            logger.warning("âš ï¸ matplotlibæˆ–shapæœªå®‰è£…ï¼Œæ— æ³•ç»˜å›¾")
    
    def plot_waterfall(self, X: np.ndarray, feature_names: List[str],
                      idx: int = 0, save_path: Optional[str] = None):
        """
        ç»˜åˆ¶ç€‘å¸ƒå›¾ï¼ˆå•æ ·æœ¬è§£é‡Šï¼‰
        
        Args:
            X: ç‰¹å¾æ•°æ®
            feature_names: ç‰¹å¾åç§°
            idx: æ ·æœ¬ç´¢å¼•
            save_path: ä¿å­˜è·¯å¾„
        """
        try:
            import shap
            import matplotlib.pyplot as plt
            
            if self.shap_values is None:
                self.explain(X, feature_names)
            
            plt.figure(figsize=(10, 6))
            
            # åˆ›å»ºExplanationå¯¹è±¡
            explanation = shap.Explanation(
                values=self.shap_values[idx],
                base_values=self.explainer.expected_value,
                data=X[idx],
                feature_names=feature_names
            )
            
            shap.waterfall_plot(explanation, show=False)
            plt.title(f"SHAP Waterfall Plot (Sample {idx})")
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"ğŸ“Š SHAPç€‘å¸ƒå›¾å·²ä¿å­˜: {save_path}")
            
            plt.show()
            
        except ImportError:
            logger.warning("âš ï¸ matplotlibæˆ–shapæœªå®‰è£…ï¼Œæ— æ³•ç»˜å›¾")
    
    def get_feature_interactions(self, X: np.ndarray, feature_names: List[str],
                                top_n: int = 10) -> pd.DataFrame:
        """
        åˆ†æç‰¹å¾äº¤äº’ä½œç”¨
        
        Args:
            X: ç‰¹å¾æ•°æ®
            feature_names: ç‰¹å¾åç§°
            top_n: è¿”å›å‰Nä¸ªäº¤äº’
        
        Returns:
            ç‰¹å¾äº¤äº’DataFrame
        """
        try:
            import shap
            
            if self.shap_values is None:
                self.explain(X, feature_names)
            
            # è®¡ç®—ç‰¹å¾äº¤äº’SHAPå€¼
            interaction_values = self.explainer.shap_interaction_values(X)
            
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªè¾“å‡º
            if isinstance(interaction_values, list):
                interaction_values = interaction_values[0]
            
            # è®¡ç®—å¹³å‡äº¤äº’å¼ºåº¦
            mean_interaction = np.abs(interaction_values).mean(axis=0)
            
            # æå–éå¯¹è§’çº¿å…ƒç´ ï¼ˆç‰¹å¾é—´äº¤äº’ï¼‰
            interactions = []
            n = len(feature_names)
            for i in range(n):
                for j in range(i+1, n):
                    interactions.append({
                        'feature_1': feature_names[i],
                        'feature_2': feature_names[j],
                        'interaction_strength': mean_interaction[i, j]
                    })
            
            # æ’åº
            interactions_df = pd.DataFrame(interactions)
            interactions_df = interactions_df.sort_values('interaction_strength', 
                                                          ascending=False)
            
            return interactions_df.head(top_n)
            
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾äº¤äº’åˆ†æå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def generate_report(self, X: np.ndarray, feature_names: List[str],
                       n_samples: int = 5) -> str:
        """
        ç”Ÿæˆè§£é‡ŠæŠ¥å‘Š
        
        Args:
            X: ç‰¹å¾æ•°æ®
            feature_names: ç‰¹å¾åç§°
            n_samples: è§£é‡Šçš„æ ·æœ¬æ•°
        
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        if self.shap_values is None:
            self.explain(X, feature_names)
        
        report = []
        report.append("="*70)
        report.append("SHAPæ¨¡å‹è§£é‡ŠæŠ¥å‘Š")
        report.append("="*70)
        
        # 1. å…¨å±€ç‰¹å¾é‡è¦æ€§
        report.append("\nã€å…¨å±€ç‰¹å¾é‡è¦æ€§ã€‘")
        importance_df = self._calculate_feature_importance(feature_names)
        report.append(importance_df.head(10).to_string(index=False))
        
        # 2. å•æ ·æœ¬è§£é‡Š
        report.append(f"\nã€å•æ ·æœ¬è§£é‡Š (å‰{n_samples}ä¸ªæ ·æœ¬)ã€‘")
        for i in range(min(n_samples, len(X))):
            explanation = self.explain_single_prediction(X, feature_names, idx=i)
            report.append(f"\næ ·æœ¬ {i}:")
            report.append(f"  åŸºå‡†å€¼: {explanation['base_value']:.6f}")
            report.append(f"  é¢„æµ‹å€¼: {explanation['prediction']:.6f}")
            report.append(f"  ä¸»è¦å½±å“å› ç´ :")
            for feat in explanation['top_features'][:5]:
                report.append(f"    - {feat['feature']}: {feat['shap_value']:.6f} ({feat['impact']})")
        
        report.append("\n" + "="*70)
        
        return "\n".join(report)


class PredictionExplainer:
    """é¢„æµ‹ç»“æœè§£é‡Šå™¨ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä¾èµ–SHAPï¼‰"""
    
    def __init__(self, model):
        self.model = model
    
    def explain_with_feature_importance(self, X: np.ndarray, 
                                       feature_names: List[str]) -> pd.DataFrame:
        """
        ä½¿ç”¨æ¨¡å‹å†…ç½®çš„ç‰¹å¾é‡è¦æ€§è¿›è¡Œè§£é‡Š
        
        Args:
            X: ç‰¹å¾æ•°æ®
            feature_names: ç‰¹å¾åç§°
        
        Returns:
            ç‰¹å¾é‡è¦æ€§DataFrame
        """
        importance = self.model.get_feature_importance()
        
        if not importance:
            logger.warning("âš ï¸ æ¨¡å‹æ²¡æœ‰æä¾›ç‰¹å¾é‡è¦æ€§")
            return pd.DataFrame()
        
        # æ˜ å°„åˆ°ç‰¹å¾å
        df = pd.DataFrame([
            {'feature': feature_names[i], 'importance': imp}
            for i, imp in enumerate(importance.values())
            if i < len(feature_names)
        ])
        
        df = df.sort_values('importance', ascending=False)
        
        return df
    
    def explain_prediction_change(self, X_base: np.ndarray, 
                                  X_changed: np.ndarray,
                                  feature_names: List[str],
                                  changed_features: List[str]) -> Dict[str, Any]:
        """
        è§£é‡Šç‰¹å¾å˜åŒ–å¯¹é¢„æµ‹çš„å½±å“
        
        Args:
            X_base: åŸºå‡†ç‰¹å¾
            X_changed: æ”¹å˜åçš„ç‰¹å¾
            feature_names: æ‰€æœ‰ç‰¹å¾å
            changed_features: æ”¹å˜çš„ç‰¹å¾å
        
        Returns:
            å˜åŒ–è§£é‡Š
        """
        # åŸºå‡†é¢„æµ‹
        pred_base = self.model.predict(X_base.reshape(1, -1))[0]
        
        # æ”¹å˜åé¢„æµ‹
        pred_changed = self.model.predict(X_changed.reshape(1, -1))[0]
        
        # å˜åŒ–é‡
        change = pred_changed - pred_base
        
        # æ”¹å˜çš„ç‰¹å¾å€¼
        feature_changes = []
        for feat in changed_features:
            idx = feature_names.index(feat)
            old_val = X_base[idx]
            new_val = X_changed[idx]
            feature_changes.append({
                'feature': feat,
                'old_value': old_val,
                'new_value': new_val,
                'change': new_val - old_val,
                'change_pct': (new_val - old_val) / old_val * 100 if old_val != 0 else 0
            })
        
        return {
            'prediction_base': pred_base,
            'prediction_changed': pred_changed,
            'prediction_change': change,
            'prediction_change_pct': change / pred_base * 100 if pred_base != 0 else 0,
            'feature_changes': feature_changes,
            'direction': 'ä¸Šæ¶¨' if change > 0 else 'ä¸‹è·Œ' if change < 0 else 'æŒå¹³'
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("="*70)
    print("SHAPæ¨¡å‹è§£é‡Šæ€§æ¨¡å—")
    print("="*70)
    
    print("\nâœ… SHAPè§£é‡Šå™¨æ¨¡å—å°±ç»ª")
    print("   â€¢ æ”¯æŒæ ‘æ¨¡å‹è§£é‡Š (XGBoost/LightGBM)")
    print("   â€¢ æ”¯æŒæ·±åº¦å­¦ä¹ æ¨¡å‹è§£é‡Š (LSTM/Transformer)")
    print("   â€¢ æä¾›æ‘˜è¦å›¾ã€ç€‘å¸ƒå›¾ã€äº¤äº’åˆ†æ")
    print("="*70)
