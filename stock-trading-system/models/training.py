"""
æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°æ¨¡å—
åŒ…å«æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€äº¤å‰éªŒè¯ã€æ€§èƒ½è¯„ä¼°
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import logging
import pickle
import json
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, model, model_name: str):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: æ¨¡å‹å®ä¾‹ (LSTMModel/XGBoostModel/TransformerModel)
            model_name: æ¨¡å‹åç§°
        """
        self.model = model
        self.model_name = model_name
        self.training_history = {}
        self.metrics = {}
        
    def prepare_data(self, df: pd.DataFrame, feature_cols: List[str],
                    target_col: str = 'close', 
                    sequence_length: int = 60,
                    train_ratio: float = 0.8,
                    val_ratio: float = 0.1) -> Dict[str, Any]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            df: ç‰¹å¾æ•°æ®
            feature_cols: ç‰¹å¾åˆ—å
            target_col: ç›®æ ‡åˆ—å
            sequence_length: åºåˆ—é•¿åº¦ï¼ˆç”¨äºLSTM/Transformerï¼‰
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
        
        Returns:
            åˆ’åˆ†å¥½çš„æ•°æ®å­—å…¸
        """
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡ä½œä¸ºç›®æ ‡
        df = df.copy()
        df['target'] = df[target_col].shift(-1) / df[target_col] - 1
        df = df.dropna()
        
        # å‡†å¤‡ç‰¹å¾
        X = df[feature_cols].values
        y = df['target'].values
        
        # æ—¶é—´åºåˆ—åˆ’åˆ†ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
        n = len(X)
        train_size = int(n * train_ratio)
        val_size = int(n * val_ratio)
        
        X_train = X[:train_size]
        y_train = y[:train_size]
        
        X_val = X[train_size:train_size + val_size]
        y_val = y[train_size:train_size + val_size]
        
        X_test = X[train_size + val_size:]
        y_test = y[train_size + val_size:]
        
        # å¦‚æœæ˜¯åºåˆ—æ¨¡å‹ï¼Œéœ€è¦reshape
        if hasattr(self.model, 'sequence_length'):
            X_train = self._create_sequences(X_train, self.model.sequence_length)
            y_train = y_train[self.model.sequence_length:]
            
            X_val = self._create_sequences(X_val, self.model.sequence_length)
            y_val = y_val[self.model.sequence_length:]
            
            X_test = self._create_sequences(X_test, self.model.sequence_length)
            y_test = y_test[self.model.sequence_length:]
        
        logger.info(f"ğŸ“Š æ•°æ®åˆ’åˆ†å®Œæˆ:")
        logger.info(f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        logger.info(f"   éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
        logger.info(f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        return {
            'X_train': X_train, 'y_train': y_train,
            'X_val': X_val, 'y_val': y_val,
            'X_test': X_test, 'y_test': y_test,
            'feature_cols': feature_cols
        }
    
    def _create_sequences(self, X: np.ndarray, seq_length: int) -> np.ndarray:
        """åˆ›å»ºåºåˆ—æ•°æ®"""
        sequences = []
        for i in range(len(X) - seq_length + 1):
            sequences.append(X[i:i + seq_length])
        return np.array(sequences)
    
    def train(self, data: Dict[str, Any], 
             save_path: Optional[str] = None) -> Dict[str, Any]:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            data: å‡†å¤‡å¥½çš„æ•°æ®å­—å…¸
            save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
        
        Returns:
            è®­ç»ƒç»“æœ
        """
        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒ {self.model_name} æ¨¡å‹...")
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.train(
            data['X_train'], data['y_train'],
            data['X_val'], data['y_val']
        )
        
        self.training_history = history
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        test_metrics = self.evaluate(
            data['X_test'], data['y_test']
        )
        
        self.metrics = {
            'test': test_metrics,
            'train_size': len(data['X_train']),
            'val_size': len(data['X_val']),
            'test_size': len(data['X_test'])
        }
        
        # ä¿å­˜æ¨¡å‹
        if save_path:
            self.save_model(save_path)
        
        logger.info(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        logger.info(f"   æµ‹è¯•é›† MSE: {test_metrics['mse']:.6f}")
        logger.info(f"   æµ‹è¯•é›† MAE: {test_metrics['mae']:.6f}")
        logger.info(f"   æµ‹è¯•é›† RÂ²: {test_metrics['r2']:.4f}")
        
        return {
            'history': history,
            'metrics': self.metrics
        }
    
    def evaluate(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•ç›®æ ‡
        
        Returns:
            è¯„ä¼°æŒ‡æ ‡
        """
        # é¢„æµ‹
        y_pred = self.model.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # æ–¹å‘å‡†ç¡®ç‡ï¼ˆé¢„æµ‹æ¶¨è·Œæ–¹å‘ï¼‰
        direction_true = np.sign(y_test[1:] - y_test[:-1])
        direction_pred = np.sign(y_pred[1:] - y_pred[:-1])
        direction_accuracy = np.mean(direction_true == direction_pred)
        
        metrics = {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'direction_accuracy': direction_accuracy
        }
        
        return metrics
    
    def cross_validate(self, df: pd.DataFrame, feature_cols: List[str],
                      target_col: str = 'close',
                      n_splits: int = 5,
                      sequence_length: int = 60) -> Dict[str, List[float]]:
        """
        æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
        
        Args:
            df: ç‰¹å¾æ•°æ®
            feature_cols: ç‰¹å¾åˆ—å
            target_col: ç›®æ ‡åˆ—å
            n_splits: äº¤å‰éªŒè¯æŠ˜æ•°
            sequence_length: åºåˆ—é•¿åº¦
        
        Returns:
            å„æŠ˜çš„è¯„ä¼°æŒ‡æ ‡
        """
        logger.info(f"ğŸ”„ å¼€å§‹ {n_splits} æŠ˜æ—¶é—´åºåˆ—äº¤å‰éªŒè¯...")
        
        # å‡†å¤‡æ•°æ®
        df = df.copy()
        df['target'] = df[target_col].shift(-1) / df[target_col] - 1
        df = df.dropna()
        
        X = df[feature_cols].values
        y = df['target'].values
        
        # æ—¶é—´åºåˆ—åˆ†å‰²
        tscv = TimeSeriesSplit(n_splits=n_splits)
        
        cv_results = {
            'mse': [], 'rmse': [], 'mae': [], 'r2': [],
            'direction_accuracy': []
        }
        
        for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):
            logger.info(f"   ç¬¬ {fold}/{n_splits} æŠ˜...")
            
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            
            # åºåˆ—æ¨¡å‹ç‰¹æ®Šå¤„ç†
            if hasattr(self.model, 'sequence_length'):
                X_train_seq = self._create_sequences(X_train, sequence_length)
                y_train_seq = y_train[sequence_length:]
                X_val_seq = self._create_sequences(X_val, sequence_length)
                y_val_seq = y_val[sequence_length:]
                
                # ä¸´æ—¶åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹
                from copy import deepcopy
                fold_model = deepcopy(self.model)
                fold_model.is_trained = False
                fold_model.model = None
                
                # è®­ç»ƒ
                fold_model.train(X_train_seq, y_train_seq)
                
                # è¯„ä¼°
                metrics = self._evaluate_fold(fold_model, X_val_seq, y_val_seq)
            else:
                # éåºåˆ—æ¨¡å‹
                fold_model = deepcopy(self.model)
                fold_model.is_trained = False
                fold_model.model = None
                if hasattr(fold_model, 'build_model'):
                    fold_model.build_model()
                
                fold_model.train(X_train, y_train)
                metrics = self._evaluate_fold(fold_model, X_val, y_val)
            
            for key in cv_results:
                cv_results[key].append(metrics[key])
        
        # è®¡ç®—å¹³å‡å€¼
        cv_summary = {
            key: {'mean': np.mean(values), 'std': np.std(values)}
            for key, values in cv_results.items()
        }
        
        logger.info(f"âœ… äº¤å‰éªŒè¯å®Œæˆ!")
        for metric, stats in cv_summary.items():
            logger.info(f"   {metric}: {stats['mean']:.4f} (Â±{stats['std']:.4f})")
        
        return cv_summary
    
    def _evaluate_fold(self, model, X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, float]:
        """è¯„ä¼°å•æŠ˜"""
        y_pred = model.predict(X_val)
        
        mse = mean_squared_error(y_val, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_val, y_pred)
        r2 = r2_score(y_val, y_pred)
        
        direction_true = np.sign(y_val[1:] - y_val[:-1])
        direction_pred = np.sign(y_pred[1:] - y_pred[:-1])
        direction_accuracy = np.mean(direction_true == direction_pred)
        
        return {
            'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2,
            'direction_accuracy': direction_accuracy
        }
    
    def save_model(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        self.model.save(path)
        
        # ä¿å­˜è®­ç»ƒä¿¡æ¯
        info = {
            'model_name': self.model_name,
            'training_history': self.training_history,
            'metrics': self.metrics,
            'timestamp': datetime.now().isoformat()
        }
        
        info_path = path.replace('.pkl', '_info.json').replace('.pt', '_info.json')
        with open(info_path, 'w') as f:
            json.dump(info, f, indent=2, default=str)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {path}")
    
    def get_feature_importance(self, feature_names: List[str]) -> Optional[pd.DataFrame]:
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        importance = self.model.get_feature_importance()
        
        if not importance:
            return None
        
        # æ˜ å°„åˆ°ç‰¹å¾å
        df_importance = pd.DataFrame([
            {'feature': feature_names[int(k.split('_')[1])], 'importance': v}
            for k, v in importance.items() if k.startswith('feature_')
        ])
        
        df_importance = df_importance.sort_values('importance', ascending=False)
        
        return df_importance


class ModelComparison:
    """æ¨¡å‹å¯¹æ¯”è¯„ä¼°"""
    
    def __init__(self):
        self.results = {}
    
    def add_result(self, model_name: str, metrics: Dict[str, float],
                  training_time: float = None):
        """æ·»åŠ æ¨¡å‹ç»“æœ"""
        self.results[model_name] = {
            'metrics': metrics,
            'training_time': training_time
        }
    
    def compare(self) -> pd.DataFrame:
        """å¯¹æ¯”æ‰€æœ‰æ¨¡å‹"""
        comparison_data = []
        
        for model_name, result in self.results.items():
            row = {'model': model_name}
            row.update(result['metrics'])
            if result['training_time']:
                row['training_time'] = result['training_time']
            comparison_data.append(row)
        
        df = pd.DataFrame(comparison_data)
        
        # æ’åºï¼ˆæŒ‰R2é™åºï¼‰
        if 'r2' in df.columns:
            df = df.sort_values('r2', ascending=False)
        
        return df
    
    def get_best_model(self, metric: str = 'r2') -> str:
        """è·å–æœ€ä½³æ¨¡å‹"""
        comparison = self.compare()
        
        if metric in comparison.columns:
            # å¯¹äºè¯¯å·®æŒ‡æ ‡ï¼Œè¶Šå°è¶Šå¥½ï¼›å¯¹äºR2ç­‰ï¼Œè¶Šå¤§è¶Šå¥½
            if metric in ['mse', 'rmse', 'mae']:
                best_idx = comparison[metric].idxmin()
            else:
                best_idx = comparison[metric].idxmax()
            
            return comparison.loc[best_idx, 'model']
        
        return None
    
    def plot_comparison(self, save_path: Optional[str] = None):
        """å¯è§†åŒ–å¯¹æ¯”ç»“æœ"""
        try:
            import matplotlib.pyplot as plt
            
            df = self.compare()
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            
            metrics = ['mse', 'mae', 'r2', 'direction_accuracy']
            titles = ['MSE (è¶Šä½è¶Šå¥½)', 'MAE (è¶Šä½è¶Šå¥½)', 
                     'RÂ² (è¶Šé«˜è¶Šå¥½)', 'Direction Accuracy (è¶Šé«˜è¶Šå¥½)']
            
            for idx, (metric, title) in enumerate(zip(metrics, titles)):
                if metric in df.columns:
                    ax = axes[idx // 2, idx % 2]
                    bars = ax.bar(df['model'], df[metric])
                    ax.set_title(title)
                    ax.set_ylabel(metric.upper())
                    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
                    
                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar in bars:
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height,
                               f'{height:.4f}',
                               ha='center', va='bottom', fontsize=8)
            
            plt.tight_layout()
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"ğŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
            
            plt.show()
            
        except ImportError:
            logger.warning("âš ï¸ matplotlibæœªå®‰è£…ï¼Œæ— æ³•ç»˜å›¾")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("="*70)
    print("æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°æ¨¡å—")
    print("="*70)
    
    # ç¤ºä¾‹ï¼šåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 1000
    n_features = 30
    
    df = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )
    df['close'] = np.random.randn(n_samples).cumsum() + 100
    
    feature_cols = [f'feature_{i}' for i in range(n_features)]
    
    print(f"\nğŸ“Š æ¨¡æ‹Ÿæ•°æ®: {n_samples} æ ·æœ¬, {n_features} ç‰¹å¾")
    
    # ç¤ºä¾‹ï¼šåˆ›å»ºæ¨¡å‹å’Œè®­ç»ƒå™¨
    from models.predictors import XGBoostModel
    
    model = XGBoostModel({
        'n_estimators': 100,
        'max_depth': 4,
        'learning_rate': 0.1
    })
    
    trainer = ModelTrainer(model, "XGBoost_Example")
    
    # å‡†å¤‡æ•°æ®
    data = trainer.prepare_data(df, feature_cols, train_ratio=0.7, val_ratio=0.15)
    
    print(f"\nâœ… Phase 3 æ¨¡å‹è®­ç»ƒæ¨¡å—å°±ç»ª")
    print("="*70)
